Oisin Doherty
oisind
#1269085

Individual Status Report – Week 7

“While we haven’t gotten a fully working implementation where all our individual pieces can communicate yet, I’ll try to push harder to get this done by the end of the week, considering we don’t really have anything novel “due” for this next project. The sooner we get a build ready that we can actually test on and have people interact with, the sooner we get data that we can use to show the efficacy of our tools. I’m more than happy to take up some more responsibility on the project to make sure that we get this done by next Monday if it means that we can get closer to ending our rapid prototyping phase and move to incorporating feedback on a more polished system.”

The original specification that we thought of for the scraper was to have a tab separated list of commands--this turned out to be a bad idea. Abhinav and I are discussing alternative formats to encode our data in, and XML seems like a good way to do so. The actual encoding and decoding shouldn’t be difficult, but I’m unsure as to whether python and Java have built-in libraries to handle the format. Now that we’re approaching a phase where we can start integration testing, I can change the scraper to pull from the most recent StackOverflow posts instead of pulling from the top ones. I was able to pull and parse the most popular questions to give to Lauren as sample data to test the website, but now we can move towards setting up a longer term solution to gathering data. There are two major concerns that I’ve brought to light while working on this project: the time it takes for a question to be sufficiently answered and the quality of StackOverflow as a data source. In the original Tellina repository, a lot of the scraped StackOverflow questions ended up going unused because of how question-specific or malformed the commands were—an issue we’re currently running into. After getting this set up, I imagine that we need to give new questions some time to actually be answered before we attempt to parse them for an answer. I think the best thing I can do at the moment is to start scraping the oldest questions, and work on verifying the commands in the current database. I imagine that there are libraries or utilities online that will tell me if a bash command is malformed rather than having to run each command in a virtual environment.

Primarily, our goal is to get a working version of our system set up for Thursday. This requires me to have our scraper parsing the oldest (and most likely well-answered) StackOverflow questions autonomously and have a good output format for our verification files. After we get it working and set up completely, I can work on verifying that the bash commands that we have gathered are valid. As a longer term goal if we have extra time towards the end, we can attempt to integrate another source for natural language / command pairs into our user interface.
